{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_text_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMOZYzZnCx93HJTgLufNdi7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/injoon-pij/pytorch-learning/blob/master/pytorch_text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbP2wCdiHp58"
      },
      "source": [
        "# 1) Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnvEkOgmID6p"
      },
      "source": [
        "텍스트 분류는 RNN의 다-대-일(Many-to-One) 문제에 속함. \n",
        "* 모든 시점(time step)에 대해서 입력을 받지만 최종 시점의 RNN 셀만이 은닉 상태를 출력하고, 이것이 출력층으로 가서 활성화 함수를 통해 정답을 고르는 문제\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh2M1rqkGivH"
      },
      "source": [
        "텍스트 분류 관점에서 앞서 배운 RNN 코드의 timesteps와 input_dim, 그리고 hidden_size를 해석해보면 다음과 같다\n",
        "\n",
        "```python\n",
        "nn.RNN(input_size, hidden_size, batch_first=True)\n",
        "```\n",
        "\n",
        "* hidden_size = 출력의 크기(output_dim).\n",
        "* timesteps = 시점의 수 = 각 문서에서의 단어 수.\n",
        "* input_size = 입력의 크기 = 각 단어의 벡터 표현의 차원 수."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUGlr_Z2H7RV"
      },
      "source": [
        "# 2) IMDB Movie Review Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "001yEf6PIjX7"
      },
      "source": [
        "IMDB의 리뷰 데이터는 리뷰에 대한 텍스트와 해당 리뷰가 긍정인 경우 1을 부정인 경우 0으로 표시한 레이블로 구성된 데이터\n",
        "\n",
        "파이토치에서는 해당 IMDB 영화 리뷰 데이터를 바로 다운로드 할 수 있도록 지원하고 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STlpMscbGPuh",
        "outputId": "bdf958cb-85e8-4345-8f3e-472355c0d3ef"
      },
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data, datasets\n",
        "import random\n",
        "\n",
        "# seed\n",
        "SEED = 5\n",
        "random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "\n",
        "# hyperparameter\n",
        "BATCH_SIZE = 64\n",
        "lr = 0.001\n",
        "EPOCHS = 10\n",
        "\n",
        "# cpu/gpu\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(\"cpu와 cuda 중 다음 기기로 학습함:\", DEVICE)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cpu와 cuda 중 다음 기기로 학습함: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iux6gOPKJFcg"
      },
      "source": [
        "## 2.1 Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0H5dLleJYHm"
      },
      "source": [
        "### 2.1.1 Data Field"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkCgFzYQjRKi"
      },
      "source": [
        "* LABEL\n",
        " * use_vocab : dataset.IMDB의 레이블 데이터는 'neg', 'pos' 형태, 즉 텍스트 형태로 되어있으므로 데이터 학습 시 레이블을 정수 인덱스로 바꾸기 위해 단어 집합 딕셔너리를 만들 것임 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2iBvRRlJFAP"
      },
      "source": [
        "# 필드 정의\n",
        "TEXT = data.Field(sequential=True,\n",
        "                  lower = True,\n",
        "                  batch_first = True)\n",
        "\n",
        "LABEL = data.Field(sequential= False,\n",
        "                   batch_first = True,\n",
        "                   is_target = True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1fKOPgZcKN3q"
      },
      "source": [
        "### 2.1.2 Data Load\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yu9s4CEeK66S"
      },
      "source": [
        "torchtext.legacy.datasets을 통해 IMDB 리뷰 데이터를 다운로드할 수 있다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eZ1mjXcKMdZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a99c041-59d4-4167-90bf-7b6d680429d6"
      },
      "source": [
        "# 데이터를 다운받는 동시에 훈련 데이터와 테스트 데이터를 분할해 dataset 형태로 저장\n",
        "trainset, testset = datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:05<00:00, 15.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOOQ97uGL6gY",
        "outputId": "6277056a-7a4c-44b9-ab83-aee1224c9ace"
      },
      "source": [
        "print(len(trainset))\n",
        "print(len(testset))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n",
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXd8ifUIlFo-",
        "outputId": "76e373bb-4535-449c-d94b-6a73e7b7a31f"
      },
      "source": [
        "print(vars(trainset[0]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['in', 'terms', 'of', 'the', 'arts,', 'the', '1970s', 'were', 'a', 'very', 'turbulent', 'era.', 'in', 'literature', 'and', 'the', 'visual', 'arts,', 'it', 'was', 'the', 'closing', 'of', 'a', 'great', 'fifty', 'or', 'sixty', 'year', 'period', 'of', 'creativity', 'that', 'has', 'yet', 'to', 'be', 'restarted.', 'in', 'music', 'it', 'was', 'a', 'decade', 'that', 'many', 'see', 'as', 'a', 'low', 'point,', 'due', 'to', 'corporate', 'rock', 'and', 'disco.', 'on', 'television', 'it', 'was', 'a', 'golden', 'age', 'for', 'situation', 'comedies,', 'from', 'the', 'odd', 'couple', 'to', 'the', 'mary', 'tyler', 'moore', 'show', 'to', 'm*a*s*h', 'to', 'all', 'in', 'the', 'family,', 'but', 'in', 'film', 'it', 'was', 'even', 'a', 'greater', 'period', 'of', 'creativity,', 'in', 'all', 'genres,', 'that', 'saw', 'the', 'rise', 'of', 'the', 'american', 'auteur-', 'directors', 'like', 'robert', 'altman,', 'francis', 'ford', 'coppola,', 'and', 'martin', 'scorsese-', 'from', 'the', 'ashes', 'of', 'the', 'old', 'studio', 'systems', 'that', 'had', 'dominated', 'hollywood', 'for', 'over', 'half', 'a', 'century.', 'these', 'directors', 'wanted', 'to', 'craft', 'literate,', 'arts', 'films', 'for', 'the', 'masses,', 'of', 'the', 'sort', 'that', 'had', 'been', 'staples', 'in', 'europe', 'since', 'the', 'end', 'of', 'the', 'second', 'world', 'war.', 'yet,', 'the', 'studios', 'were', 'trying', 'to', 'keep', 'pace,', 'with', 'socially', 'aware', 'films', 'of', 'the', 'sort', 'not', 'seen', 'since', 'the', '1930s.<br', '/><br', '/>but,', 'unlike', 'the', 'films', 'of', 'the', '1930s,', 'starring', 'actors', 'like', 'jimmy', 'cagney', 'and', 'john', 'garfield', '(usually', 'co-starring', 'the', 'dead', 'end', 'kids),', 'that', 'dealt', 'with', 'social', 'issues', 'in', 'a', 'gritty', 'realistic', 'way,', 'or', 'as', 'realistic', 'as', 'one', 'could', 'get', 'on', 'a', 'sound', 'stage,', 'the', 'social', 'consciousness', 'of', 'the', 'late', '1960s', 'and', 'early', '1970s', 'manifested', 'itself', 'most', 'in', 'science', 'fiction', 'films,', 'which', 'allowed', 'the', 'left', 'wing', 'of', 'hollywood', 'to', 'preach', 'to', 'the', 'masses', 'under', 'the', 'guise', 'of', 'what', 'most', 'considered', 'little', 'above', 'comic', 'strip', 'entertainment.', 'there', 'was', 'precedent', 'for', 'this', 'approach,', 'for', 'several', 'of', 'the', 'flying', 'saucer', 'films', 'of', 'the', '1950s', 'dealt', 'with', 'the', 'political', 'zeitgeist', 'of', 'the', 'mccarthy', 'era-', 'most', 'notably', 'the', 'day', 'the', 'earth', 'stood', 'still', 'and', 'invasion', 'of', 'the', 'body', 'snatchers.', 'and', 'the', 'early', '1960s', 'saw', 'rod', 'serling', 'constantly', 'subverting', 'the', 'political', 'conservatism', 'of', 'the', 'time', 'by', 'casting', 'social', 'issues', 'into', 'science', 'fiction', 'settings', 'on', 'his', 'classic', 'sci', 'fi', 'television', 'anthology', 'show', 'the', 'twilight', 'zone.', 'among', 'the', 'studio', 'offerings', 'of', 'this', 'time', 'were', 'the', 'ecologically', 'sensitive', 'silent', 'running;', 'george', \"lucas's\", 'first', 'film', 'thx', '1138,', 'which', 'dealt', 'with', 'consumerism,', 'group', 'think,', 'and', 'existentialism;', 'and', \"logan's\", 'run,', 'which', 'hammered', 'away', 'at', 'communism', 'and', 'state', 'control', 'versus', 'the', 'rights', 'of', 'an', 'individual.', 'some', 'of', 'the', \"film's\", 'references', 'are', 'quite', 'heavyhanded-', 'and', 'reek', 'of', 'the', 'then', 'current', 'arab', 'oil', 'crisis', 'and', 'rampant', 'inflation.', 'a', 'few', 'jarred', 'strawberries', 'cost', '$150,', 'and', 'soylent', 'rations', 'its', 'assorted', 'colored', 'foods-', 'soylent', 'yellow,', 'soylent', 'red,', 'and', 'the', 'new', 'soylent', 'green,', 'reputedly', 'made', 'from', \"'the\", 'finest', 'undersea', \"growth,'\", 'in', 'a', 'manner', 'not', 'unlike', 'the', 'gas', 'rationing', 'of', 'the', 'time.', 'scenes', 'of', 'food', 'riots', 'are', 'eerie', 'echoes', 'of', 'the', 'oil', 'riots', 'at', 'many', 'gas', 'stations', 'during', 'the', 'year', 'of', 'the', \"film's\", 'release,', 'and', 'the', 'scenes', 'of', 'crowding,', 'and', 'bodies,', 'live', 'and', 'dead,', 'lying', 'all', 'about', 'are', 'still', 'chilling,', 'as', 'well', 'as', 'influential.', 'a', 'later', 'film', 'like', 'escape', 'from', 'new', 'york', 'is', 'an', 'obvious', 'progeny.', 'the', 'rest', 'of', 'the', 'script,', 'by', 'stanley', 'r.', 'greenberg,', 'however,', 'is', 'rather', 'pedestrian,', 'and', 'fairly', 'standard', 'for', 'a', 'dystopian', 'flick,', 'but', 'fleischer', 'and', 'cinematographer', 'richard', 'h.', 'kline', 'do', 'a', 'great', 'job', 'of', 'filling', 'the', 'screen', 'with', 'interesting', 'images', 'and', 'sounds,', 'to', 'spice', 'things', 'up.', 'the', 'use', 'of', 'soft,', 'dimly', 'lit', 'visuals,', 'murkily', 'filtered,', 'add', 'a', 'stygian', 'feel', 'to', 'the', 'new', 'york', 'of', 'the', 'film,', 'almost', 'like', 'a', 'colorized', 'version', 'of', 'carl', 'theodor', \"dreyer's\", 'vampyr.', 'the', 'only', 'light', 'in', 'the', 'film', 'comes', 'from', 'artificial', 'sources,', 'and', 'were', 'it', 'not', 'for', 'the', 'fashion', 'faux', 'pas', 'the', 'film', 'could', 'truly', 'seem', 'timeless.<br', '/><br', '/>the', 'end', 'of', 'the', 'film,', 'where', 'thorn', 'sneaks', 'into', 'the', 'processing', 'plant', 'where', 'human', 'corpses', 'are', 'made', 'into', 'soylent', 'green', 'wafers,', 'is', 'both', 'chilling,', 'and', 'oddly', 'drama-less.', 'in', 'the', 'end,', 'the', 'soylent', 'minions', 'hunt', 'thorn', 'down,', 'but', 'he', 'survives', 'long', 'enough', 'to', 'utter', 'the', \"film's\", 'catchphrase', 'to', 'chief', 'hatcher.', 'yet,', 'one', 'does', 'not', 'know', 'if', 'it', 'is', 'enough,', 'for', 'hatcher', 'has', 'already', 'been', 'co-opted,', 'and', 'has', 'a', 'track', 'record', 'of', 'taking', 'the', 'easy', 'way', 'out.', 'yet,', 'that', 'fact,', 'and', 'its', 'ambiguity,', 'shows', 'that', 'the', 'film', 'does', 'not', 'recapitulate', 'its', \"characters'\", 'dilemmas,', 'and', 'has', 'a', 'depth', 'many', 'later,', 'better', 'made', 'films,', 'sci', 'fi', 'or', 'not,', 'do', 'not', 'have.', 'it', 'is', 'also', 'why', 'soylent', 'green', 'is', 'still', 'a', 'film', 'worth', 'watching.'], 'label': 'pos'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uB6Qon1lu0Q"
      },
      "source": [
        "### 2.1.3 Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8XVvdpAV9oD"
      },
      "source": [
        "# 단어 집합 생성\n",
        "TEXT.build_vocab(trainset, min_freq = 5)\n",
        "LABEL.build_vocab(trainset)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOZLMrVykUD6",
        "outputId": "e9e4ab24-d995-425e-dc67-b264453ba5a4"
      },
      "source": [
        "LABEL.vocab.stoi"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "defaultdict(<bound method Vocab._default_unk_index of <torchtext.legacy.vocab.Vocab object at 0x7f2777f84250>>,\n",
              "            {'<unk>': 0, 'neg': 1, 'pos': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_96TbhcGlc9_"
      },
      "source": [
        "* dataset.IMDB의 레이블 데이터는 'neg', 'pos' 형태로, 즉 텍스트 형태로 되어있으므로 추후 학습 시 정답 레이블을 정수 인덱스로 바꾸기 위해 단어 집합 딕셔너리를 만듬"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJNKiVhnwbnf",
        "outputId": "d0d7c825-31b9-4912-88b9-903c805d6c58"
      },
      "source": [
        "vocab_size = len(TEXT.vocab)\n",
        "n_classes = 2\n",
        "print('단어 집합의 크기 : {}'.format(vocab_size))\n",
        "print('클래스의 개수 : {}'.format(n_classes))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "단어 집합의 크기 : 46159\n",
            "클래스의 개수 : 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYW4nwYClzlw"
      },
      "source": [
        "### 2.1.4 DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8nSYLt3ZzOX"
      },
      "source": [
        "# 모델 평가 위한 검증 데이터 분할\n",
        "trainset, valset = trainset.split(split_ratio=0.8)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzVNrJzcQ1Mc"
      },
      "source": [
        "* dataset.split : 비율에 따라 데이터셋 분할"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhVLQUK9ZzrM"
      },
      "source": [
        "train_iter, val_iter, test_iter = data.BucketIterator.splits(\n",
        "                                            (trainset, valset, testset), \n",
        "                                            batch_size=BATCH_SIZE,\n",
        "                                            shuffle=True, \n",
        "                                            repeat=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TC8q4vWXoS4B"
      },
      "source": [
        "* BucketIterator(tuple of datasets) : Defines an iterator that __batches examples of similar lengths together__\n",
        " * 일반 Iterator와 다른 점은, 입력 데이터의 시퀀스 길이가 서로 다른 경우에 서로 길이가 비슷한 데이터들끼리 모아 미니배치를 구성하게 만든다는 것임\n",
        " * splits : 여러 dataset으로부터 각각의 Iterator 생성\n",
        "\n",
        "* repeat = False : 미니배치 연산자들이 한 에폭(dataset의 처음부터 끝)을 다 끝내면 iterate를 멈춤\n",
        " * repeat = True : 에폭이 끝나도 연산자 반복이 무한히 진행되므로, 에폭 단위가 아닌 iteration 단위로 성능을 측정하고자 할 때 주로 사용. 이때 인위적으로 iteration을 멈춰주지 않으면 무한히 반복하므로 주의."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BwL-7JFtsGhS",
        "outputId": "f23a7439-0239-4d3e-899d-0bed33961a07"
      },
      "source": [
        "print('훈련 데이터의 미니 배치의 개수 : {}'.format(len(train_iter)))\n",
        "print('테스트 데이터의 미니 배치의 개수 : {}'.format(len(test_iter)))\n",
        "print('검증 데이터의 미니 배치의 개수 : {}'.format(len(val_iter)))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터의 미니 배치의 개수 : 313\n",
            "테스트 데이터의 미니 배치의 개수 : 391\n",
            "검증 데이터의 미니 배치의 개수 : 79\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFw-lS740U_o"
      },
      "source": [
        "### 2.1.5 Modeling(GRU)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "du8McyzH0oqg"
      },
      "source": [
        "GRU는 LSTM과 같은 은닉층에 게이트가 추가된 RNN 모델 중 하나이다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI96_RLfvP0V"
      },
      "source": [
        "class GRU(nn.Module):\n",
        "\n",
        "    def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "        super(GRU, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "        self.dropout = nn.Dropout(dropout_p)\n",
        "        self.gru = nn.GRU(embed_dim, self.hidden_dim,\n",
        "                          num_layers=self.n_layers,\n",
        "                          batch_first=True)\n",
        "        self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        # (배치 크기, 시퀀스 길이) => (배치 크기, 시퀀스 길이, 임베딩 차원)\n",
        "        x = self.embed(x)\n",
        "\n",
        "        # 최초 은닉 상태값를 0벡터로 초기화\n",
        "        h_0 = self._init_state(batch_size=x.size(0))\n",
        "\n",
        "        # x.shape() => (배치 크기, 시퀀스 길이, 은닉 상태의 크기)\n",
        "        x, _ = self.gru(x, h_0)\n",
        "\n",
        "        # 마지막 time-step의 은닉 상태만 가져옴\n",
        "        # (배치 크기, 시퀀스 길이, 은닉 상태의 크기) => (배치 크기, 은닉 상태의 크기)\n",
        "        h_t = x[:,-1,:]\n",
        "\n",
        "        self.dropout(h_t)\n",
        "\n",
        "        # (배치 크기, 은닉 상태의 크기) -> (배치 크기, 출력층의 크기)\n",
        "        logit = self.out(h_t)\n",
        "\n",
        "        return logit\n",
        "\n",
        "    def _init_state(self, batch_size=1):\n",
        "        weight = next(self.parameters()).data\n",
        "        return weight.new_zeros(self.n_layers, batch_size, self.hidden_dim)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKyfN6OIQ_TG"
      },
      "source": [
        "* new_zeros() : 입력된 사이즈와 같은 형태로 새로운 제로 텐서를 반환\n",
        " * 입력 사이즈 형태는 tuple 이나 list\n",
        "\n",
        "* 필요한 크기의 제로텐서를 새로 정의하지 않고 굳이 모델 내부의 파라미터를 new_zeros()로 받아 다시 만든 이유는 new() 함수가 반환하는 새로 구성된 텐서는 __기존 텐서와 동일한 dtype, device를 유지한 채로 반환되기 때문__\n",
        " * 모델의 device를 GPU로 정의해도 모델 내부에서 새로운 텐서를 따로 정의하면 해당 텐서는 device가 CPU로 정의되기 때문에, GPU로 정의된 모델 내부의 파라미터를 기반으로 new() 함수 사용한 것 \n",
        " * 또한 class 내부에 텐서를 새로 정의하려면 class 내부에 torch를 불필요하게 import 해야 하므로 이를 지양하고, 이미 존재하는 텐서를 사용하기 위한 것\n",
        "\n",
        "```python\n",
        "# new_zeros()\n",
        "tensor = torch.tensor((), dtype=torch.float64)\n",
        "tensor\n",
        ">>> tensor([], dtype=torch.float64)\n",
        "\n",
        "tensor.new_zeros((2, 3))\n",
        ">>> tensor([[ 0.,  0.,  0.],\n",
        "            [ 0.,  0.,  0.]], dtype=torch.float64)\n",
        "\n",
        "tensor.new_zeros([5,6])\n",
        ">>> tensor([[0., 0., 0., 0., 0., 0.],\n",
        "            [0., 0., 0., 0., 0., 0.],\n",
        "            [0., 0., 0., 0., 0., 0.],\n",
        "            [0., 0., 0., 0., 0., 0.],\n",
        "            [0., 0., 0., 0., 0., 0.]], dtype=torch.float64)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlR3k2w2wSkN"
      },
      "source": [
        "model = GRU(n_layers = 1, hidden_dim = 256, n_vocab = vocab_size, embed_dim = 128, n_classes = n_classes, dropout_p = 0.5).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# DEVICE = cuda인 경우, model의 parameter도 cuda 연산인지 확인\n",
        "# next(model.parameters()).data.device\n",
        "# >>> device(type='cuda', index=0)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSX6nBl_wUYh"
      },
      "source": [
        "def train(model, optimizer, train_iter):\n",
        "    model.train() # tells your model that you are training the model\n",
        "    for b, batch in enumerate(train_iter):\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1)  # 레이블 값을 0과 1로 변환\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logit = model(x)\n",
        "\n",
        "        loss = F.cross_entropy(logit, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vl4WzMw_G50Z"
      },
      "source": [
        "* ```y.data.sub_(1)``` : 현재 레이블값이 'neg' = 1, 'pos' = 2 형태로 되어있으므로 긍/부정 이중분류를 적용하기 위해 레이블값을 0과 1로 변환해줌"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfdjmveGwejF"
      },
      "source": [
        "def evaluate(model, val_iter):\n",
        "    \"\"\"evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    corrects, total_loss = 0, 0\n",
        "    for batch in val_iter:\n",
        "        x, y = batch.text.to(DEVICE), batch.label.to(DEVICE)\n",
        "        y.data.sub_(1) # 레이블 값을 0과 1로 변환\n",
        "\n",
        "        logit = model(x)\n",
        "\n",
        "        loss = F.cross_entropy(logit, y, reduction='sum')\n",
        "        total_loss += loss.item() # .item() : 손실이 갖고 있는 스칼라 값을 가져옴 \n",
        "        corrects += (logit.max(dim = 1)[1].view(y.size()).data == y.data).sum()\n",
        "    size = len(val_iter.dataset)\n",
        "    avg_loss = total_loss / size\n",
        "    avg_accuracy = 100.0 * corrects / size\n",
        "    return avg_loss, avg_accuracy"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouvEib7LIwke"
      },
      "source": [
        "* ```with torch.no_grad()``` vs. ```model.eval()```\n",
        "\n",
        " * ```with torch.no_grad()``` : 모델 평가(추론) 시에 명령어들을 ```with torch.no_grad()```에 포함시키게 되면 Pytorch는 autograd engine을 꺼버린다. 이 말은 더 이상 자동으로 gradient를 트래킹하지 않는다는 말이다. 물론 추론 과정에서 loss.backward()를 통해 역전파를 진행하지 않는다면 굳이 ```torch.no_grad()```에 포함시키지 않아도 gradient를 계산하지 않을 것이지만, __torch.no_grad()의 주된 목적은 autograd를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함이다.__ 그래서 일반적으로 inference를 진행할 때는 ```with torch.no_grad()``` 로 명령어로 감싼다.\n",
        "\n",
        " * ```model.eval()``` : ```model.eval()```의 역할은 ```with torch.no_grad()```와 약간 다르다. 학습 시에는 동작해야하지만, 추론 시에는 동작하지 않는 Dropout layer나 BatchNorm layer처럼 모델링 시 상황에 따라 다르게 동작하는 layer들이 존재한다. ```model.eval()```는 이런 layer들의 동작을 추론 상황으로 바꿔준다는 목적으로 사용된다. \n",
        " \n",
        " * 따라서, 우리가 보통 원하는 모델의 동작을 위해서는 위의 두 가지를 모두 사용해야하는 것이 맞다.\n",
        "\n",
        "* ```cross_entropy(... reduction = 'sum')```\n",
        " * reduction (string, optional) – Specifies the reduction to apply to the output\n",
        "   * 'none': no reduction will be applied\n",
        "   * 'mean': the sum of the output will be divided by the number of elements in the output\n",
        "   * 'sum': the output will be summed\n",
        "\n",
        "* ```corrects += (logit.max(1)[1].view(y.size()).data == y.data).sum()```\n",
        " * .view(y.size()) : view로 출력값의 사이즈를 y의 사이즈와 같게 조정 (사실 위 시에서는 조정하지 않아도 이미 동일함)\n",
        " * .data == .detach() : 기존 텐서를 복사함\n",
        "   * 위 계산에서는기존 텐서 y 를 그대로 사용해도 상관은 없음\n",
        "   * 단, pytorch에서는 .data 보다는 .detach() 를 사용하기를 권장함 [https://subinium.github.io/pytorch-Tensor-Variable/] "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MThX7d3qwg7t",
        "outputId": "bed371b3-907e-4770-acad-b8dcc3f57636"
      },
      "source": [
        "best_val_loss = None\n",
        "for e in range(1, EPOCHS+1):\n",
        "    train(model, optimizer, train_iter)\n",
        "    val_loss, val_accuracy = evaluate(model, val_iter)\n",
        "\n",
        "    print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (e, val_loss, val_accuracy))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "    if not best_val_loss or val_loss < best_val_loss:\n",
        "        if not os.path.isdir(\"snapshot\"):\n",
        "            os.makedirs(\"snapshot\")\n",
        "        torch.save(model.state_dict(), './snapshot/txtclassification.pt')\n",
        "        best_val_loss = val_loss"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1] val loss :  0.70 | val accuracy : 50.44\n",
            "[Epoch: 2] val loss :  0.69 | val accuracy : 50.36\n",
            "[Epoch: 3] val loss :  0.71 | val accuracy : 49.40\n",
            "[Epoch: 4] val loss :  0.49 | val accuracy : 77.52\n",
            "[Epoch: 5] val loss :  0.35 | val accuracy : 85.50\n",
            "[Epoch: 6] val loss :  0.34 | val accuracy : 86.02\n",
            "[Epoch: 7] val loss :  0.38 | val accuracy : 85.72\n",
            "[Epoch: 8] val loss :  0.42 | val accuracy : 85.98\n",
            "[Epoch: 9] val loss :  0.50 | val accuracy : 85.46\n",
            "[Epoch: 10] val loss :  0.49 | val accuracy : 85.98\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_LwzMdC_OhCq"
      },
      "source": [
        "* ```model.state_dict()```\n",
        " * Returns a dictionary containing a whole state of the module. Both parameters and persistent buffers are included.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CPLnCdwb4TAo",
        "outputId": "19086125-7f00-4f57-9c64-8e822e06ced1"
      },
      "source": [
        "# model.state_dict() 확인\n",
        "for key in model.state_dict().keys():\n",
        "  size = model.state_dict()[key].shape\n",
        "  print('{} size :'.format(key), list(size))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "embed.weight size : [46159, 128]\n",
            "gru.weight_ih_l0 size : [768, 128]\n",
            "gru.weight_hh_l0 size : [768, 256]\n",
            "gru.bias_ih_l0 size : [768]\n",
            "gru.bias_hh_l0 size : [768]\n",
            "out.weight size : [2, 256]\n",
            "out.bias size : [2]\n"
          ]
        }
      ]
    }
  ]
}